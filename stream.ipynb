{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = '''\n",
    "Hello [-.//PU-]{+!//PU+} {+I　'm//MW+} [-Fine//C-]{+fine//C+} {+,//PU+} thanks {+.//PU+} [-and//C-]{+And//C+} you ?\n",
    "Line up the bottles in rows of 4 , then 3 , then 2 , then 1 {+.//PU+} Get a frisbee per [-each//D-] player and allow to take two shots on each turn .\n",
    "Each pin {+knocked　down//MW+} is one point .\n",
    "{+For　a//MW+} [-Strike//C-]{+strike//C+} {+,//PU+} {+the　player//MW+} gets to take two more shots and [-add//AG-]{+adds//AG+} all the points together .\n",
    "The player with the most points is {+the//AR+} winner .\n",
    "Honey and ginger : [-it//PS-]{+they//PS+} [-is//AG-]{+are//AG+} [-natual//SP-]{+natural//SP+} food and good for sore throats [-,　no//PU-]{+,　no//PU+} side - effects , take a [-aspoonful//SP-]{+spoonful//SP+} anytime when you need .\n",
    "Garlic and Echinacea tea : drink it when {+you//PS+} have infection [-,　it//PU-]{+,　it//PU+} is simple but {+an//AR+} excellent antibiotic .\n",
    "Hot mixture of vinegar , olive oil and eucalyptus : place it on aches and pains [-,　it//PU-]{+,　it//PU+} is {+a//AR+} fast and effective way to relieve aches and pains .\n",
    "[-everyone//C-]{+Everyone//C+} may use it in {+his　or　her//PS+} daily life .\n",
    "First , John asked Isabella not to marry him and [-giving　a　chance//XC-]{+her　to　give　him　the　chance//XC+} to prove himself to have {+the//AR+} ability to make [-the//AR-]{+a//AR+} happy life for her .\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 把標點符號edit token，變成after\n",
    "# 2. 簡化修改標記:  {+word+}, [-word-], [-word>>word+}\n",
    "# 3. 再斷句一次\n",
    "# 4. 把一句多錯誤，變成多句個含一個錯誤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import fileinput\n",
    "import re\n",
    "from pprint import pprint\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def simple_tag(tags):\n",
    "    if tags['d'] and tags['i']:    # d >> i\n",
    "        return '[-{d}>>{i}+}}'.format(d=tags['d'], i=tags['i'])\n",
    "    elif tags['d']:\n",
    "        return '[-{d}-]'.format(d=tags['d'])\n",
    "    elif tags['i']:\n",
    "        return '{{+{i}+}}'.format(i=tags['i'])\n",
    "    else:\n",
    "        print(\"Should not be here in simple_tag()\")\n",
    "\n",
    "re_tag = r'(\\[-(?P<d>.+)//(?P<d_tag>.+)-\\])?({\\+(?P<i>.+)//(?P<i_tag>.+)\\+})?'\n",
    "def correct_punc(line):\n",
    "    new_line = []\n",
    "    for token in line.split(' '):\n",
    "        tags = re.match(re_tag, token).groupdict()\n",
    "        if not tags['d_tag'] and not tags['i_tag']:  # no edit, 原字\n",
    "            new_line.append(token)\n",
    "        elif tags['i_tag'] == 'PU':                  # PU 錯誤類型不管，因此遇到 PU 則改成正確句子，只管被新增的符號\n",
    "            for item in tags['i'].split():           # TODO: 照原本寫法，不確定 split 用意\n",
    "                new_line.append(item)\n",
    "        elif tags['d_tag'] != 'PU':                  # error type not 'PU'\n",
    "            new_line.append(simple_tag(tags))   \n",
    "    return' '.join(new_line)\n",
    "\n",
    "def restore_line_break(text):\n",
    "    return text.replace('<br/>', '\\n').replace('<br>', '\\n').replace('<br />', '\\n')\n",
    "\n",
    "def restore_xmlescape(text):\n",
    "    while '&amp;' in text:\n",
    "        text = text.replace('&amp;', '&')\n",
    "    text = text.replace('&quote;', '\"')\n",
    "    text = text.replace('&quot;', '\"')\n",
    "    text = text.replace('&nbsp;', ' ')\n",
    "    text = text.replace('&lt;', '<')\n",
    "    text = text.replace('&gt;', '>')\n",
    "    return text\n",
    "\n",
    "def mask_edits(text):\n",
    "    edits, tokens = [], []\n",
    "    for token in text.split(' '):\n",
    "        if token.startswith('{+') or token.startswith('[-'):\n",
    "            masked_token = \"{{{0}}}\".format(len(edits))\n",
    "            tokens.append(masked_token)\n",
    "            edits.append(token)\n",
    "        else:\n",
    "            tokens.append(token.replace('{', '{{').replace('}', '}}'))\n",
    "    return ' '.join(tokens), edits\n",
    "\n",
    "\n",
    "def tokenize_doc(text):\n",
    "    text = restore_line_break(text)\n",
    "    text = restore_xmlescape(text)\n",
    "\n",
    "    # mask edit tokens first to prevent being segmented\n",
    "    # I have {+a+} pen. => I have {0} pen.\n",
    "    text_masked, edits = mask_edits(text)\n",
    "\n",
    "    for line in text_masked.splitlines():\n",
    "        for sent in sent_tokenize(line.strip()):\n",
    "            # restore masked edit tokens and return\n",
    "            yield sent.format(*edits) \n",
    "\n",
    "def to_after(tokens):\n",
    "    def to_after_token(token):\n",
    "        token = token.replace('\\u3000', ' ')\n",
    "        if token.endswith('-]'):\n",
    "            return None\n",
    "        elif token.endswith('+}'):\n",
    "            return token[token.rfind('>>')+2:-2]  if token.startswith('[-') else token[2:-2]  \n",
    "        else:\n",
    "            return token\n",
    "    return ' '.join(token for token in map(to_after_token, tokens) if token)\n",
    "\n",
    "new_data = []\n",
    "if __name__ == '__main__':\n",
    "    for line in test_data.split('\\n'): # fileinput.input():\n",
    "        simple_line = correct_punc(line.strip()) # remove PU\n",
    "        for sent in tokenize_doc(simple_line):\n",
    "            # after_sent = to_after(sent.split(' ')) # correct sentence\n",
    "            tokens = sent.split(' ')\n",
    "            for i, token in enumerate(tokens):\n",
    "                if token.startswith('[-') or token.startswith('{+'):\n",
    "                    new_sent = to_after(tokens[:i]) + ' ' + token + ' ' + to_after(tokens[i+1:])\n",
    "                    new_data.append(new_sent.strip())\n",
    "\n",
    "\n",
    "# pprint(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fileinput\n",
    "import spacy\n",
    "from spacy.tokens import Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhitespaceTokenizer(object):\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __call__(self, text):\n",
    "        words = text.split(' ')\n",
    "        # All tokens 'own' a subsequent space character in this tokenizer\n",
    "        spaces = [True] * len(words)\n",
    "        return Doc(self.vocab, words=words, spaces=spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "# nlp = spacy.load('en_core_web_lg')\n",
    "nlp.tokenizer = WhitespaceTokenizer(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "\n",
      "        (Insert) None\t->\tI\n",
      "        Sent:\tI 'm fine , thanks . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\t'm\t'm\tVBP\n",
      "        Target:\tI\t-PRON-\tPRP\tnsubj\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\t'm\n",
      "        Sent:\tI 'm fine , thanks . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\t'm\t'm\tVBP\n",
      "        Target:\t'm\t'm\tVBP\tROOT\n",
      "\tChild:\tI\t-PRON-\tPRP\tnsubj\n",
      "\tChild:\tfine\tfine\tJJ\tacomp\n",
      "\tChild:\t,\t,\t,\tpunct\n",
      "\tChild:\tthanks\tthank\tNNS\tnpadvmod\n",
      "\tChild:\t.\t.\t.\tpunct\n",
      "====================================\n",
      "\n",
      "        (Replace) Fine\t->\tfine\n",
      "        Sent:\tI 'm fine , thanks . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\t'm\t'm\tVBP\n",
      "        Target:\tfine\tfine\tJJ\tacomp\n",
      "====================================\n",
      "\n",
      "        (Replace) and\t->\tAnd\n",
      "        Sent:\tAnd you ? \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tyou\t-PRON-\tPRP\n",
      "        Target:\tAnd\tand\tCC\tcc\n",
      "====================================\n",
      "\n",
      "        (Delete/pre) each\t->\tNone\n",
      "        Sent:\tGet a frisbee per player and allow to take two shots on each turn . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tfrisbee\tfrisbee\tNN\n",
      "        Target:\tper\tper\tIN\tprep\n",
      "\tChild:\tplayer\tplayer\tNN\tpobj\n",
      "\tDelete:\teach\teach\tDT\n",
      "====================================\n",
      "\n",
      "        (Delete/post) each\t->\tNone\n",
      "        Sent:\tGet a frisbee per player and allow to take two shots on each turn . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tper\tper\tIN\n",
      "        Target:\tplayer\tplayer\tNN\tpobj\n",
      "\tDelete:\teach\teach\tDT\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\tknocked\n",
      "        Sent:\tEach pin knocked down is one point . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tis\tbe\tVBZ\n",
      "        Target:\tknocked\tknock\tVBD\tcsubj\n",
      "\tChild:\tpin\tpin\tNN\tnsubj\n",
      "\tChild:\tdown\tdown\tRP\tprt\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\tdown\n",
      "        Sent:\tEach pin knocked down is one point . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tknocked\tknock\tVBD\n",
      "        Target:\tdown\tdown\tRP\tprt\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\tFor\n",
      "        Sent:\tFor a strike , the player gets to take two more shots and adds all the points together . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgets\tget\tVBZ\n",
      "        Target:\tFor\tfor\tIN\tprep\n",
      "\tChild:\tstrike\tstrike\tNN\tpobj\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\ta\n",
      "        Sent:\tFor a strike , the player gets to take two more shots and adds all the points together . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tstrike\tstrike\tNN\n",
      "        Target:\ta\ta\tDT\tdet\n",
      "====================================\n",
      "\n",
      "        (Replace) Strike\t->\tstrike\n",
      "        Sent:\tFor a strike , the player gets to take two more shots and adds all the points together . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tFor\tfor\tIN\n",
      "        Target:\tstrike\tstrike\tNN\tpobj\n",
      "\tChild:\ta\ta\tDT\tdet\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\tthe\n",
      "        Sent:\tFor a strike , the player gets to take two more shots and adds all the points together . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tplayer\tplayer\tNN\n",
      "        Target:\tthe\tthe\tDT\tdet\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\tplayer\n",
      "        Sent:\tFor a strike , the player gets to take two more shots and adds all the points together . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgets\tget\tVBZ\n",
      "        Target:\tplayer\tplayer\tNN\tnsubj\n",
      "\tChild:\tthe\tthe\tDT\tdet\n",
      "====================================\n",
      "\n",
      "        (Replace) add\t->\tadds\n",
      "        Sent:\tFor a strike , the player gets to take two more shots and adds all the points together . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgets\tget\tVBZ\n",
      "        Target:\tadds\tadd\tVBZ\tconj\n",
      "\tChild:\tpoints\tpoint\tNNS\tdobj\n",
      "\tChild:\ttogether\ttogether\tRB\tadvmod\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\tthe\n",
      "        Sent:\tThe player with the most points is the winner . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\twinner\twinner\tNN\n",
      "        Target:\tthe\tthe\tDT\tdet\n",
      "====================================\n",
      "\n",
      "        (Replace) it\t->\tthey\n",
      "        Sent:\tHoney and ginger : they are natural food and good for sore throats , no side - effects , take a spoonful anytime when you need . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tare\tbe\tVBP\n",
      "        Target:\tthey\t-PRON-\tPRP\tnsubj\n",
      "====================================\n",
      "\n",
      "        (Replace) is\t->\tare\n",
      "        Sent:\tHoney and ginger : they are natural food and good for sore throats , no side - effects , take a spoonful anytime when you need . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tare\tbe\tVBP\n",
      "        Target:\tare\tbe\tVBP\tROOT\n",
      "\tChild:\tHoney\thoney\tNNP\tdep\n",
      "\tChild:\t:\t:\t:\tpunct\n",
      "\tChild:\tthey\t-PRON-\tPRP\tnsubj\n",
      "\tChild:\tfood\tfood\tNN\tattr\n",
      "\tChild:\t,\t,\t,\tpunct\n",
      "\tChild:\ttake\ttake\tVB\tconj\n",
      "\tChild:\t.\t.\t.\tpunct\n",
      "====================================\n",
      "\n",
      "        (Replace) natual\t->\tnatural\n",
      "        Sent:\tHoney and ginger : they are natural food and good for sore throats , no side - effects , take a spoonful anytime when you need . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tfood\tfood\tNN\n",
      "        Target:\tnatural\tnatural\tJJ\tamod\n",
      "====================================\n",
      "\n",
      "        (Replace) aspoonful\t->\tspoonful\n",
      "        Sent:\tHoney and ginger : they are natural food and good for sore throats , no side - effects , take a spoonful anytime when you need . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tanytime\tanytime\tNN\n",
      "        Target:\tspoonful\tspoonful\tJJ\tamod\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\tyou\n",
      "        Sent:\tGarlic and Echinacea tea : drink it when you have infection , it is simple but an excellent antibiotic . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\thave\thave\tVBP\n",
      "        Target:\tyou\t-PRON-\tPRP\tnsubj\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\tan\n",
      "        Sent:\tGarlic and Echinacea tea : drink it when you have infection , it is simple but an excellent antibiotic . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tantibiotic\tantibiotic\tNN\n",
      "        Target:\tan\tan\tDT\tdet\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\ta\n",
      "        Sent:\tHot mixture of vinegar , olive oil and eucalyptus : place it on aches and pains , it is a fast and effective way to relieve aches and pains . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tway\tway\tNN\n",
      "        Target:\ta\ta\tDT\tdet\n",
      "====================================\n",
      "\n",
      "        (Replace) everyone\t->\tEveryone\n",
      "        Sent:\tEveryone may use it in his or her daily life . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tuse\tuse\tVB\n",
      "        Target:\tEveryone\teveryone\tNN\tnsubj\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\this\n",
      "        Sent:\tEveryone may use it in his or her daily life . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tlife\tlife\tNN\n",
      "        Target:\this\t-PRON-\tPRP$\tposs\n",
      "\tChild:\tor\tor\tCC\tcc\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\tor\n",
      "        Sent:\tEveryone may use it in his or her daily life . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\this\t-PRON-\tPRP$\n",
      "        Target:\tor\tor\tCC\tcc\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\ther\n",
      "        Sent:\tEveryone may use it in his or her daily life . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tlife\tlife\tNN\n",
      "        Target:\ther\t-PRON-\tPRP$\tposs\n",
      "====================================\n",
      "\n",
      "        (Replace) giving\t->\ther\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\thim\t-PRON-\tPRP\n",
      "        Target:\ther\t-PRON-\tPRP\tconj\n",
      "====================================\n",
      "\n",
      "        (Replace) a\t->\ther\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\thim\t-PRON-\tPRP\n",
      "        Target:\ther\t-PRON-\tPRP\tconj\n",
      "====================================\n",
      "\n",
      "        (Replace) chance\t->\ther\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\thim\t-PRON-\tPRP\n",
      "        Target:\ther\t-PRON-\tPRP\tconj\n",
      "====================================\n",
      "\n",
      "        (Replace) giving\t->\tto\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgive\tgive\tVB\n",
      "        Target:\tto\tto\tTO\taux\n",
      "====================================\n",
      "\n",
      "        (Replace) a\t->\tto\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgive\tgive\tVB\n",
      "        Target:\tto\tto\tTO\taux\n",
      "====================================\n",
      "\n",
      "        (Replace) chance\t->\tto\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgive\tgive\tVB\n",
      "        Target:\tto\tto\tTO\taux\n",
      "====================================\n",
      "\n",
      "        (Replace) giving\t->\tgive\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tmarry\tmarry\tVB\n",
      "        Target:\tgive\tgive\tVB\tadvcl\n",
      "\tChild:\tto\tto\tTO\taux\n",
      "\tChild:\thim\t-PRON-\tPRP\tdative\n",
      "\tChild:\tchance\tchance\tNN\tdobj\n",
      "====================================\n",
      "\n",
      "        (Replace) a\t->\tgive\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tmarry\tmarry\tVB\n",
      "        Target:\tgive\tgive\tVB\tadvcl\n",
      "\tChild:\tto\tto\tTO\taux\n",
      "\tChild:\thim\t-PRON-\tPRP\tdative\n",
      "\tChild:\tchance\tchance\tNN\tdobj\n",
      "====================================\n",
      "\n",
      "        (Replace) chance\t->\tgive\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tmarry\tmarry\tVB\n",
      "        Target:\tgive\tgive\tVB\tadvcl\n",
      "\tChild:\tto\tto\tTO\taux\n",
      "\tChild:\thim\t-PRON-\tPRP\tdative\n",
      "\tChild:\tchance\tchance\tNN\tdobj\n",
      "====================================\n",
      "\n",
      "        (Replace) giving\t->\thim\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgive\tgive\tVB\n",
      "        Target:\thim\t-PRON-\tPRP\tdative\n",
      "====================================\n",
      "\n",
      "        (Replace) a\t->\thim\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgive\tgive\tVB\n",
      "        Target:\thim\t-PRON-\tPRP\tdative\n",
      "====================================\n",
      "\n",
      "        (Replace) chance\t->\thim\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgive\tgive\tVB\n",
      "        Target:\thim\t-PRON-\tPRP\tdative\n",
      "====================================\n",
      "\n",
      "        (Replace) giving\t->\tthe\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tchance\tchance\tNN\n",
      "        Target:\tthe\tthe\tDT\tdet\n",
      "====================================\n",
      "\n",
      "        (Replace) a\t->\tthe\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tchance\tchance\tNN\n",
      "        Target:\tthe\tthe\tDT\tdet\n",
      "====================================\n",
      "\n",
      "        (Replace) chance\t->\tthe\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tchance\tchance\tNN\n",
      "        Target:\tthe\tthe\tDT\tdet\n",
      "====================================\n",
      "\n",
      "        (Replace) giving\t->\tchance\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgive\tgive\tVB\n",
      "        Target:\tchance\tchance\tNN\tdobj\n",
      "\tChild:\tthe\tthe\tDT\tdet\n",
      "\tChild:\tprove\tprove\tVB\tacl\n",
      "====================================\n",
      "\n",
      "        (Replace) a\t->\tchance\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgive\tgive\tVB\n",
      "        Target:\tchance\tchance\tNN\tdobj\n",
      "\tChild:\tthe\tthe\tDT\tdet\n",
      "\tChild:\tprove\tprove\tVB\tacl\n",
      "====================================\n",
      "\n",
      "        (Replace) chance\t->\tchance\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tgive\tgive\tVB\n",
      "        Target:\tchance\tchance\tNN\tdobj\n",
      "\tChild:\tthe\tthe\tDT\tdet\n",
      "\tChild:\tprove\tprove\tVB\tacl\n",
      "====================================\n",
      "\n",
      "        (Insert) None\t->\tthe\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tability\tability\tNN\n",
      "        Target:\tthe\tthe\tDT\tdet\n",
      "====================================\n",
      "\n",
      "        (Replace) the\t->\ta\n",
      "        Sent:\tFirst , John asked Isabella not to marry him and her to give him the chance to prove himself to have the ability to make a happy life for her . \n",
      "        \n",
      "        \tToken\tLemma\tTag\tDep(to head)\n",
      "        Head:\tlife\tlife\tNN\n",
      "        Target:\ta\ta\tDT\tdet\n"
     ]
    }
   ],
   "source": [
    "# 用來抓 edit word\n",
    "re_words = r'(\\[-(?P<d>.+)-\\]|{\\+(?P<i>.+)\\+}|\\[-(?P<rd>.+)>>(?P<ri>.+)\\+})?'\n",
    "def correct(origin_tokens):\n",
    "    correct_tokens, pairs = [], []\n",
    "    for ot in origin_tokens:\n",
    "        ot = ot.replace('\\u3000', ' ')\n",
    "        words = re.match(re_words, ot).groupdict()\n",
    "        if words['rd'] and words['ri']:\n",
    "            for ri in words['ri'].split():\n",
    "                for rd in words['rd'].split():\n",
    "                    pairs.append(('Replace', rd, ri, len(correct_tokens))) # 最後一欄位是對應 correct_tokens 用的\n",
    "                correct_tokens.append(ri)\n",
    "        elif words['i']:\n",
    "            for i in words['i'].split():\n",
    "                pairs.append(('Insert', None, i, len(correct_tokens)))\n",
    "                correct_tokens.append(i)\n",
    "        elif words['d']:\n",
    "            pairs.append(('Delete', words['d'], None, len(correct_tokens)))\n",
    "        else:\n",
    "            correct_tokens.append(ot)\n",
    "            \n",
    "    return correct_tokens, pairs\n",
    "\n",
    "    \n",
    "def format_edit(edit):\n",
    "    edit_type, origin_token, new_token, correct_token, correct_sent = edit\n",
    "    \n",
    "    template = '''\n",
    "        ({edit_type}) {origin_token}\\t->\\t{new_token}\n",
    "        Sent:\\t{correct_sent}\n",
    "        \n",
    "        \\tToken\\tLemma\\tTag\\tDep(to head)\n",
    "        Head:\\t{head}\\t{head_lemma}\\t{head_tag}\n",
    "        Target:\\t{target_token}\\t{target_token_lemma}\\t{target_token_tag}\\t{target_token_dep}'''.format(\n",
    "               edit_type = edit_type, \n",
    "               origin_token = origin_token,\n",
    "               new_token = new_token,\n",
    "               correct_sent = correct_sent,\n",
    "               target_token = correct_token.text,\n",
    "               target_token_lemma = correct_token.lemma_,\n",
    "               target_token_tag = correct_token.tag_,\n",
    "               target_token_dep = correct_token.dep_,\n",
    "                   \n",
    "               head = correct_token.head.text,\n",
    "               head_lemma = correct_token.head.lemma_,\n",
    "               head_tag = correct_token.head.tag_)\n",
    "    \n",
    "    for child in correct_token.children:\n",
    "        template += \"\\n\\tChild:\\t{child}\\t{child_lemma}\\t{child_tag}\\t{child_dep}\".format(\n",
    "            child = child.text, child_lemma = child.lemma_, child_tag = child.tag_, child_dep = child.dep_)\n",
    "            \n",
    "    if edit_type.startswith(\"Delete\"):\n",
    "        origin_token = nlp(origin_token)\n",
    "        for ot in origin_token:\n",
    "            template += \"\\n\\tDelete:\\t{ot}\\t{ot_lemma}\\t{ot_tag}\".format(\n",
    "                    ot = ot.text, ot_lemma = ot.lemma_, ot_tag = ot.tag_)\n",
    "    return template\n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    all_edits = []\n",
    "    for line in new_data: # fileinput.input():\n",
    "        origin_tokens = line.strip().split(' ')\n",
    "        correct_tokens, pairs = correct(origin_tokens)\n",
    "        if not correct_tokens or not pairs: continue # skip no edit or empty string\n",
    "            \n",
    "        correct_tokens = nlp(' '.join(correct_tokens))\n",
    "        for pair in pairs:\n",
    "            edit_type, origin_token, new_token, index = pair\n",
    "            if edit_type == \"Delete\":\n",
    "                if index < len(correct_tokens):\n",
    "                    all_edits.append((edit_type + \"/pre\", origin_token, new_token, correct_tokens[index-1], correct_tokens.doc))\n",
    "                if index > 0:\n",
    "                    all_edits.append((edit_type + \"/post\", origin_token, new_token, correct_tokens[index], correct_tokens.doc))\n",
    "            else:\n",
    "                all_edits.append((edit_type, origin_token, new_token, correct_tokens[index], correct_tokens.doc))\n",
    "    \n",
    "    for edit in all_edits:\n",
    "        print(\"====================================\")\n",
    "        print(format_edit(edit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
